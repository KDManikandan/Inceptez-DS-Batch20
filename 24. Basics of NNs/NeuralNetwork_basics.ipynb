{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aofTCOF7p2tx"
      },
      "outputs": [],
      "source": [
        "#keras - Tensorflow\n",
        "#Pytorch\n",
        "#caffe\n",
        "#Chainer\n",
        "#..\n",
        "#.\n",
        "#.\n",
        "#."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4JmmhrQ7ydiG"
      },
      "outputs": [],
      "source": [
        "!pip install mediapipe\n",
        "import mediapipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FPM_12bdxi8p"
      },
      "outputs": [],
      "source": [
        "#!. Create env\n",
        "#2. activate env\n",
        "#3. Install your packages\n",
        "#4. jupyter notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOx_z7sbpZh-",
        "outputId": "15ffdd41-6cef-4828-b79f-678f88f1794b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
            "57026/57026 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from keras.datasets import boston_housing\n",
        "(x_train, y_train) ,(x_test,y_test) = boston_housing.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocmYgZB7yOpQ",
        "outputId": "44e644f1-e227-4323-9936-10d558f1f83a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(404, 13)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBLIqTjZySs6",
        "outputId": "984884ad-fcc5-46ad-c08f-61b628dcd989"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "404"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1oocydR4mUw"
      },
      "outputs": [],
      "source": [
        "x_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QaJbzcgm4Heu"
      },
      "outputs": [],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_mPCSza4DeK"
      },
      "source": [
        "## Creating a model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5YALCjNH4Alb"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "8AjxGeiQ4BXf"
      },
      "outputs": [],
      "source": [
        "#skeleton\n",
        "model = Sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVxVVUoe4vGG"
      },
      "source": [
        "## Adding Layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Oo-NFAQf4BUH"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Dense, Activation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "2IQOC4hC4BQ_"
      },
      "outputs": [],
      "source": [
        "model.add(Dense(10,input_shape = (13,)))\n",
        "model.add(Activation(\"sigmoid\")) #same as activation parameter below\n",
        "model.add(Dense(10,activation = 'relu'))\n",
        "model.add(Dense(10,activation= 'sigmoid'))\n",
        "model.add(Dense(1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JV0erioI7E7w"
      },
      "source": [
        "## Compile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wOcjadvA4BNp"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras import optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "kUeA7BKz7MKx"
      },
      "outputs": [],
      "source": [
        "gd = tf.keras.optimizers.SGD(learning_rate = 0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "_uFcvz419Qhf"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer = gd,loss = 'mean_squared_error',metrics = ['mse'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRUDrsIc9YLh",
        "outputId": "499031dd-e9d0-44f0-acdb-40f38175ce09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_14 (Dense)            (None, 10)                140       \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 10)                0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 10)                110       \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 10)                110       \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 371\n",
            "Trainable params: 371\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Model Summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hVVI-w59kJ-",
        "outputId": "98527a3f-d3a2-409d-9e57-d1fdb8fcdc80"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([[-0.00331455,  0.19391108, -0.0865849 , -0.32456413,  0.1330486 ,\n",
              "         -0.14420617,  0.4848103 , -0.26889855,  0.12912709,  0.05854201],\n",
              "        [ 0.36404508,  0.2947324 , -0.1818605 ,  0.17568505,  0.43452853,\n",
              "          0.17754209,  0.37265176, -0.45727977,  0.37594074, -0.48770118],\n",
              "        [-0.3661353 ,  0.07433707,  0.03243589, -0.2132768 , -0.29624587,\n",
              "          0.08050221,  0.05482537, -0.21876487, -0.16180727, -0.14222455],\n",
              "        [-0.28034633, -0.24576321,  0.44965154, -0.34526253, -0.28227887,\n",
              "         -0.15779507, -0.3069356 , -0.30253476, -0.18445173, -0.2861665 ],\n",
              "        [ 0.06243789,  0.14584255, -0.024865  , -0.0100854 ,  0.0271849 ,\n",
              "          0.40764612, -0.05842021, -0.4488281 , -0.02238241, -0.23616943],\n",
              "        [ 0.03175652, -0.3758136 , -0.3925309 ,  0.29257846,  0.48724878,\n",
              "         -0.36884257, -0.3805148 , -0.46258593, -0.2993769 , -0.37607569],\n",
              "        [ 0.00942254,  0.0888657 , -0.10879806, -0.20017815, -0.03385538,\n",
              "          0.01492453,  0.4512459 ,  0.29112715,  0.29938883, -0.14369008],\n",
              "        [-0.18633592,  0.26446086, -0.28419814,  0.08321118, -0.34881917,\n",
              "         -0.04399034,  0.18201178,  0.0136441 , -0.08562204,  0.02807909],\n",
              "        [-0.39524654, -0.17226088,  0.27097708,  0.37280774,  0.27662945,\n",
              "         -0.16748482, -0.32764935, -0.21673697, -0.42587373,  0.04676652],\n",
              "        [ 0.26910907, -0.21077397, -0.46238303, -0.108073  ,  0.48471087,\n",
              "         -0.37541103, -0.49233195,  0.10260427, -0.11412454,  0.02360255],\n",
              "        [-0.33055562, -0.08715516,  0.18647575,  0.21457171,  0.03169233,\n",
              "          0.47902858,  0.2534902 , -0.08449334, -0.28089005, -0.16758358],\n",
              "        [ 0.39203602,  0.14356917,  0.2957114 , -0.11742738,  0.50824314,\n",
              "          0.22297114, -0.19400448,  0.35205942,  0.43646932,  0.11820894],\n",
              "        [-0.08913496,  0.09074628, -0.05973428, -0.14150622, -0.37752026,\n",
              "         -0.13027385,  0.12300229,  0.30370963,  0.04049164,  0.15753096]],\n",
              "       dtype=float32),\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
              " array([[ 0.16979057,  0.0033024 , -0.5263828 , -0.08588997, -0.19285059,\n",
              "          0.02234936,  0.47962546, -0.50706947, -0.13270432,  0.2662102 ],\n",
              "        [-0.2402868 , -0.3993436 ,  0.30193532, -0.01154977, -0.4784245 ,\n",
              "          0.26033688, -0.16764829,  0.23687065, -0.33898878, -0.52660024],\n",
              "        [-0.21983069, -0.14448565,  0.09827513,  0.02931905,  0.06103075,\n",
              "          0.38061965,  0.5382123 , -0.3875645 , -0.38045365, -0.21392828],\n",
              "        [ 0.04030925,  0.0499534 , -0.3680238 ,  0.47773623,  0.41441602,\n",
              "         -0.11496469,  0.37006426,  0.18966818,  0.5216416 ,  0.10666364],\n",
              "        [ 0.39009637,  0.44178838, -0.37682423, -0.46170607, -0.43234196,\n",
              "         -0.22440282, -0.05323285, -0.20089462,  0.34592336, -0.51412547],\n",
              "        [-0.1736553 ,  0.17028618, -0.49609086, -0.06627902,  0.48243344,\n",
              "          0.14133132, -0.37232015,  0.15992731, -0.4084821 , -0.43643117],\n",
              "        [ 0.2671576 ,  0.49663305,  0.22304273, -0.2792497 ,  0.29618567,\n",
              "          0.1180467 ,  0.01604801,  0.2816307 , -0.4979528 , -0.2661113 ],\n",
              "        [ 0.2883023 ,  0.20783257,  0.17402929,  0.0419603 , -0.23825836,\n",
              "         -0.3234957 , -0.23512664,  0.42551565,  0.4139045 ,  0.4225474 ],\n",
              "        [-0.36162832,  0.18381667, -0.43306476,  0.09080094,  0.11391842,\n",
              "         -0.48736164,  0.12850761,  0.083776  , -0.31567335,  0.04332626],\n",
              "        [-0.33281344,  0.5230799 , -0.06679016, -0.4009369 , -0.05789468,\n",
              "          0.32459325, -0.33432606, -0.20792478, -0.14748406,  0.46145356]],\n",
              "       dtype=float32),\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
              " array([[ 0.17592359,  0.12547737, -0.2745525 ,  0.2884645 ,  0.43826604,\n",
              "          0.11293679,  0.23831624,  0.53025794, -0.07950792, -0.01190484],\n",
              "        [ 0.41751206, -0.10001454, -0.38813087, -0.03684556, -0.12388107,\n",
              "         -0.47361797,  0.5447973 , -0.23711208,  0.03618258,  0.00077045],\n",
              "        [-0.44115987,  0.41887945,  0.04106957,  0.03601581,  0.377581  ,\n",
              "         -0.07126355,  0.1593355 , -0.22796404,  0.12453181, -0.07162267],\n",
              "        [ 0.28070277, -0.11526844,  0.47130096, -0.06329173,  0.320646  ,\n",
              "          0.15204495,  0.3662101 ,  0.36897528,  0.35555196,  0.39400405],\n",
              "        [-0.41045567,  0.14979416, -0.01809275, -0.2599894 ,  0.46896935,\n",
              "          0.38910687,  0.07172465, -0.5250192 , -0.2519353 , -0.250243  ],\n",
              "        [ 0.33673096,  0.01974672, -0.40064505, -0.24959844,  0.13063657,\n",
              "          0.14479893,  0.48097837,  0.25156653,  0.00880343, -0.48561633],\n",
              "        [ 0.02649826,  0.20658642, -0.5077796 , -0.17066929, -0.43030035,\n",
              "         -0.03336859, -0.13769746, -0.17958018,  0.41952223,  0.20482266],\n",
              "        [ 0.5326438 ,  0.01097494, -0.23141038,  0.31600374, -0.2880057 ,\n",
              "          0.3938511 ,  0.2689076 ,  0.2782759 , -0.4951223 ,  0.25952178],\n",
              "        [-0.11423144, -0.18317237,  0.08754283,  0.30635726, -0.12411898,\n",
              "         -0.4683014 , -0.32126004,  0.45316255,  0.08778751, -0.3420947 ],\n",
              "        [-0.00262034,  0.4681406 ,  0.03804004, -0.40561545, -0.3223316 ,\n",
              "         -0.20373556,  0.43386018,  0.3444385 , -0.489433  , -0.26706097]],\n",
              "       dtype=float32),\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
              " array([[ 0.6689821 ],\n",
              "        [-0.41089538],\n",
              "        [ 0.14759398],\n",
              "        [-0.0952909 ],\n",
              "        [ 0.41846174],\n",
              "        [ 0.56789595],\n",
              "        [-0.677999  ],\n",
              "        [ 0.60000867],\n",
              "        [-0.6442904 ],\n",
              "        [-0.5585013 ]], dtype=float32),\n",
              " array([0.], dtype=float32)]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.get_weights()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kQZW7BGAWug"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dn4nvInhCAKI"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mMncW5o9z6A",
        "outputId": "3193f0a0-38c5-4398-a5a4-313c62dd1bd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "11/11 [==============================] - 1s 26ms/step - loss: 292.6039 - mse: 292.6039 - val_loss: 101.6734 - val_mse: 101.6734\n",
            "Epoch 2/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 85.9870 - mse: 85.9870 - val_loss: 87.1582 - val_mse: 87.1582\n",
            "Epoch 3/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 83.5707 - mse: 83.5707 - val_loss: 88.8233 - val_mse: 88.8233\n",
            "Epoch 4/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 83.9573 - mse: 83.9573 - val_loss: 86.4270 - val_mse: 86.4270\n",
            "Epoch 5/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 82.9912 - mse: 82.9912 - val_loss: 85.3644 - val_mse: 85.3644\n",
            "Epoch 6/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 81.8504 - mse: 81.8504 - val_loss: 81.7184 - val_mse: 81.7184\n",
            "Epoch 7/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 79.4934 - mse: 79.4934 - val_loss: 97.7587 - val_mse: 97.7587\n",
            "Epoch 8/100\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 79.3231 - mse: 79.3231 - val_loss: 80.5952 - val_mse: 80.5952\n",
            "Epoch 9/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 77.1650 - mse: 77.1650 - val_loss: 80.9710 - val_mse: 80.9710\n",
            "Epoch 10/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 84.8682 - mse: 84.8682 - val_loss: 84.6410 - val_mse: 84.6410\n",
            "Epoch 11/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 86.9088 - mse: 86.9088 - val_loss: 123.1421 - val_mse: 123.1421\n",
            "Epoch 12/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 87.4765 - mse: 87.4765 - val_loss: 88.6031 - val_mse: 88.6031\n",
            "Epoch 13/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 84.7812 - mse: 84.7812 - val_loss: 89.7822 - val_mse: 89.7822\n",
            "Epoch 14/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 85.4058 - mse: 85.4058 - val_loss: 87.6282 - val_mse: 87.6282\n",
            "Epoch 15/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 84.9106 - mse: 84.9106 - val_loss: 89.3128 - val_mse: 89.3128\n",
            "Epoch 16/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 85.2534 - mse: 85.2534 - val_loss: 96.7465 - val_mse: 96.7465\n",
            "Epoch 17/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 85.3253 - mse: 85.3253 - val_loss: 84.9190 - val_mse: 84.9190\n",
            "Epoch 18/100\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 86.0655 - mse: 86.0655 - val_loss: 85.9731 - val_mse: 85.9731\n",
            "Epoch 19/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 84.5809 - mse: 84.5809 - val_loss: 85.4213 - val_mse: 85.4213\n",
            "Epoch 20/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 85.8024 - mse: 85.8024 - val_loss: 87.4037 - val_mse: 87.4037\n",
            "Epoch 21/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 84.7582 - mse: 84.7582 - val_loss: 96.8373 - val_mse: 96.8373\n",
            "Epoch 22/100\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 85.0208 - mse: 85.0208 - val_loss: 84.4829 - val_mse: 84.4829\n",
            "Epoch 23/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 85.0841 - mse: 85.0841 - val_loss: 95.2090 - val_mse: 95.2090\n",
            "Epoch 24/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 85.6684 - mse: 85.6684 - val_loss: 91.6470 - val_mse: 91.6470\n",
            "Epoch 25/100\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 84.8940 - mse: 84.8940 - val_loss: 95.5691 - val_mse: 95.5691\n",
            "Epoch 26/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 85.0510 - mse: 85.0510 - val_loss: 89.1425 - val_mse: 89.1425\n",
            "Epoch 27/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 85.2458 - mse: 85.2458 - val_loss: 85.9796 - val_mse: 85.9796\n",
            "Epoch 28/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 84.9774 - mse: 84.9774 - val_loss: 88.3153 - val_mse: 88.3153\n",
            "Epoch 29/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 84.3806 - mse: 84.3806 - val_loss: 92.9627 - val_mse: 92.9627\n",
            "Epoch 30/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 84.8290 - mse: 84.8290 - val_loss: 90.4944 - val_mse: 90.4944\n",
            "Epoch 31/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 84.6743 - mse: 84.6743 - val_loss: 95.1993 - val_mse: 95.1993\n",
            "Epoch 32/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 85.7661 - mse: 85.7661 - val_loss: 86.8344 - val_mse: 86.8344\n",
            "Epoch 33/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 84.4330 - mse: 84.4330 - val_loss: 89.5010 - val_mse: 89.5010\n",
            "Epoch 34/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 85.2971 - mse: 85.2971 - val_loss: 92.8114 - val_mse: 92.8114\n",
            "Epoch 35/100\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 84.8734 - mse: 84.8734 - val_loss: 86.3929 - val_mse: 86.3929\n",
            "Epoch 36/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 84.5081 - mse: 84.5081 - val_loss: 87.3247 - val_mse: 87.3247\n",
            "Epoch 37/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 84.3309 - mse: 84.3309 - val_loss: 98.3594 - val_mse: 98.3594\n",
            "Epoch 38/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 85.6222 - mse: 85.6222 - val_loss: 88.3024 - val_mse: 88.3024\n",
            "Epoch 39/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 84.8127 - mse: 84.8127 - val_loss: 93.0089 - val_mse: 93.0089\n",
            "Epoch 40/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 84.7214 - mse: 84.7214 - val_loss: 84.6704 - val_mse: 84.6704\n",
            "Epoch 41/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 85.4760 - mse: 85.4760 - val_loss: 87.4352 - val_mse: 87.4352\n",
            "Epoch 42/100\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 84.6069 - mse: 84.6069 - val_loss: 90.1625 - val_mse: 90.1625\n",
            "Epoch 43/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 84.4591 - mse: 84.4591 - val_loss: 92.2152 - val_mse: 92.2152\n",
            "Epoch 44/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 84.8008 - mse: 84.8008 - val_loss: 85.9986 - val_mse: 85.9986\n",
            "Epoch 45/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 84.5974 - mse: 84.5974 - val_loss: 84.4870 - val_mse: 84.4870\n",
            "Epoch 46/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 85.2281 - mse: 85.2281 - val_loss: 87.6975 - val_mse: 87.6975\n",
            "Epoch 47/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 84.3375 - mse: 84.3375 - val_loss: 87.5758 - val_mse: 87.5758\n",
            "Epoch 48/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 87.3399 - mse: 87.3399 - val_loss: 84.4905 - val_mse: 84.4905\n",
            "Epoch 49/100\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 85.1724 - mse: 85.1724 - val_loss: 87.2260 - val_mse: 87.2260\n",
            "Epoch 50/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 84.6186 - mse: 84.6186 - val_loss: 84.5746 - val_mse: 84.5746\n",
            "Epoch 51/100\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 84.9382 - mse: 84.9382 - val_loss: 89.3180 - val_mse: 89.3180\n",
            "Epoch 52/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 84.4872 - mse: 84.4872 - val_loss: 91.5749 - val_mse: 91.5749\n",
            "Epoch 53/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 84.7966 - mse: 84.7966 - val_loss: 88.9071 - val_mse: 88.9071\n",
            "Epoch 54/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 85.0126 - mse: 85.0126 - val_loss: 86.8524 - val_mse: 86.8524\n",
            "Epoch 55/100\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 84.9813 - mse: 84.9813 - val_loss: 89.2111 - val_mse: 89.2111\n",
            "Epoch 56/100\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 84.6814 - mse: 84.6814 - val_loss: 93.4382 - val_mse: 93.4382\n",
            "Epoch 57/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 84.9571 - mse: 84.9571 - val_loss: 89.5937 - val_mse: 89.5937\n",
            "Epoch 58/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 84.8223 - mse: 84.8223 - val_loss: 88.0265 - val_mse: 88.0265\n",
            "Epoch 59/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 84.4326 - mse: 84.4326 - val_loss: 84.5181 - val_mse: 84.5181\n",
            "Epoch 60/100\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 85.1348 - mse: 85.1348 - val_loss: 84.5823 - val_mse: 84.5823\n",
            "Epoch 61/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 84.5922 - mse: 84.5922 - val_loss: 88.5607 - val_mse: 88.5607\n",
            "Epoch 62/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 84.5070 - mse: 84.5070 - val_loss: 84.7778 - val_mse: 84.7778\n",
            "Epoch 63/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 84.8417 - mse: 84.8417 - val_loss: 87.2226 - val_mse: 87.2226\n",
            "Epoch 64/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 84.7645 - mse: 84.7645 - val_loss: 88.0028 - val_mse: 88.0028\n",
            "Epoch 65/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 84.6076 - mse: 84.6076 - val_loss: 89.5660 - val_mse: 89.5660\n",
            "Epoch 66/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 84.4448 - mse: 84.4448 - val_loss: 87.8006 - val_mse: 87.8006\n",
            "Epoch 67/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 84.3062 - mse: 84.3062 - val_loss: 84.7918 - val_mse: 84.7918\n",
            "Epoch 68/100\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 85.2532 - mse: 85.2532 - val_loss: 86.0924 - val_mse: 86.0924\n",
            "Epoch 69/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 84.3716 - mse: 84.3716 - val_loss: 84.5022 - val_mse: 84.5022\n",
            "Epoch 70/100\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 85.2690 - mse: 85.2690 - val_loss: 86.0939 - val_mse: 86.0939\n",
            "Epoch 71/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 84.4881 - mse: 84.4881 - val_loss: 88.1069 - val_mse: 88.1069\n",
            "Epoch 72/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 84.7146 - mse: 84.7146 - val_loss: 92.8678 - val_mse: 92.8678\n",
            "Epoch 73/100\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 84.5026 - mse: 84.5026 - val_loss: 92.5318 - val_mse: 92.5318\n",
            "Epoch 74/100\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 88.5074 - mse: 88.5074 - val_loss: 86.5297 - val_mse: 86.5297\n",
            "Epoch 75/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 84.5854 - mse: 84.5854 - val_loss: 89.1541 - val_mse: 89.1541\n",
            "Epoch 76/100\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 84.8485 - mse: 84.8485 - val_loss: 89.0515 - val_mse: 89.0515\n",
            "Epoch 77/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 84.8471 - mse: 84.8471 - val_loss: 94.9139 - val_mse: 94.9139\n",
            "Epoch 78/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 85.7797 - mse: 85.7797 - val_loss: 85.9584 - val_mse: 85.9584\n",
            "Epoch 79/100\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 85.8520 - mse: 85.8520 - val_loss: 90.8606 - val_mse: 90.8606\n",
            "Epoch 80/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 85.2514 - mse: 85.2514 - val_loss: 91.9427 - val_mse: 91.9427\n",
            "Epoch 81/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 84.7721 - mse: 84.7721 - val_loss: 88.6655 - val_mse: 88.6655\n",
            "Epoch 82/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 84.8873 - mse: 84.8873 - val_loss: 85.4784 - val_mse: 85.4784\n",
            "Epoch 83/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 84.9119 - mse: 84.9119 - val_loss: 84.5349 - val_mse: 84.5349\n",
            "Epoch 84/100\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 84.9928 - mse: 84.9928 - val_loss: 85.3445 - val_mse: 85.3445\n",
            "Epoch 85/100\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 84.8466 - mse: 84.8466 - val_loss: 88.1217 - val_mse: 88.1217\n",
            "Epoch 86/100\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 84.9257 - mse: 84.9257 - val_loss: 86.0052 - val_mse: 86.0052\n",
            "Epoch 87/100\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 84.2788 - mse: 84.2788 - val_loss: 89.2775 - val_mse: 89.2775\n",
            "Epoch 88/100\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 84.6889 - mse: 84.6889 - val_loss: 86.3015 - val_mse: 86.3015\n",
            "Epoch 89/100\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 84.6518 - mse: 84.6518 - val_loss: 84.5229 - val_mse: 84.5229\n",
            "Epoch 90/100\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 85.0322 - mse: 85.0322 - val_loss: 87.4416 - val_mse: 87.4416\n",
            "Epoch 91/100\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 84.4118 - mse: 84.4118 - val_loss: 85.2847 - val_mse: 85.2847\n",
            "Epoch 92/100\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 84.4311 - mse: 84.4311 - val_loss: 87.1849 - val_mse: 87.1849\n",
            "Epoch 93/100\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 84.8267 - mse: 84.8267 - val_loss: 87.2587 - val_mse: 87.2587\n",
            "Epoch 94/100\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 84.3150 - mse: 84.3150 - val_loss: 89.6076 - val_mse: 89.6076\n",
            "Epoch 95/100\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 84.5376 - mse: 84.5376 - val_loss: 87.4112 - val_mse: 87.4112\n",
            "Epoch 96/100\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 84.5078 - mse: 84.5078 - val_loss: 91.3335 - val_mse: 91.3335\n",
            "Epoch 97/100\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 84.6153 - mse: 84.6153 - val_loss: 94.9999 - val_mse: 94.9999\n",
            "Epoch 98/100\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 85.3607 - mse: 85.3607 - val_loss: 89.3691 - val_mse: 89.3691\n",
            "Epoch 99/100\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 84.6464 - mse: 84.6464 - val_loss: 85.3458 - val_mse: 85.3458\n",
            "Epoch 100/100\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 86.2377 - mse: 86.2377 - val_loss: 86.0110 - val_mse: 86.0110\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ad3ee7eeb30>"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(x_train,y_train,batch_size = 32, epochs = 100,validation_split = 0.20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "clHfyN3EChlK"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fsIN1gJHCuYv"
      },
      "outputs": [],
      "source": [
        "data = load_breast_cancer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0z_Fnv28CuVn",
        "outputId": "851306ef-c696-4323-ab8d-1dfa288c6293"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
            "        1.189e-01],\n",
            "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
            "        8.902e-02],\n",
            "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
            "        8.758e-02],\n",
            "       ...,\n",
            "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
            "        7.820e-02],\n",
            "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
            "        1.240e-01],\n",
            "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
            "        7.039e-02]]), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
            "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
            "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
            "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
            "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
            "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
            "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
            "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
            "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
            "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
            "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
            "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
            "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
            "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), 'frame': None, 'target_names': array(['malignant', 'benign'], dtype='<U9'), 'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry\\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        worst/largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 0 is Mean Radius, field\\n        10 is Radius SE, field 20 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. topic:: References\\n\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.', 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
            "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
            "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
            "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
            "       'smoothness error', 'compactness error', 'concavity error',\n",
            "       'concave points error', 'symmetry error',\n",
            "       'fractal dimension error', 'worst radius', 'worst texture',\n",
            "       'worst perimeter', 'worst area', 'worst smoothness',\n",
            "       'worst compactness', 'worst concavity', 'worst concave points',\n",
            "       'worst symmetry', 'worst fractal dimension'], dtype='<U23'), 'filename': 'breast_cancer.csv', 'data_module': 'sklearn.datasets.data'}\n"
          ]
        }
      ],
      "source": [
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "sEviUCFRCuS-"
      },
      "outputs": [],
      "source": [
        "x = data.data\n",
        "y = data.target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "oUer2qiFDDoG"
      },
      "outputs": [],
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.2,random_state = 25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-m8D58xpDBze",
        "outputId": "45fa3489-f46d-408e-e308-5f653d0283fd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(569, 30)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "h4kae2WKC4bs"
      },
      "outputs": [],
      "source": [
        "model = Sequential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "o2hbXhTKC4Ym"
      },
      "outputs": [],
      "source": [
        "model.add(Dense(10,input_shape = (30,)))\n",
        "model.add(Activation(\"sigmoid\")) #same as activation parameter below\n",
        "model.add(Dense(10,activation = 'relu'))\n",
        "model.add(Dense(10,activation= 'sigmoid'))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "JAy23ATzDUFI"
      },
      "outputs": [],
      "source": [
        "gd = tf.keras.optimizers.SGD(learning_rate = 0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "U15iIg-sDUFJ"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer = gd,loss = 'binary_crossentropy',metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIRF5t79DUFK",
        "outputId": "101371d3-5f35-4c97-f17a-9666525637ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 10)                310       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 10)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                110       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                110       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 541\n",
            "Trainable params: 541\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Model Summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmX6uVvaC4TG",
        "outputId": "6ad70848-1bc9-4dde-d8fd-4d02bbc342b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "12/12 [==============================] - 3s 70ms/step - loss: 0.6577 - accuracy: 0.6374 - val_loss: 0.7197 - val_accuracy: 0.5495\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.6573 - accuracy: 0.6374 - val_loss: 0.7177 - val_accuracy: 0.5495\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.6568 - accuracy: 0.6374 - val_loss: 0.7156 - val_accuracy: 0.5495\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6562 - accuracy: 0.6374 - val_loss: 0.7149 - val_accuracy: 0.5495\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.6562 - accuracy: 0.6374 - val_loss: 0.7132 - val_accuracy: 0.5495\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.6558 - accuracy: 0.6374 - val_loss: 0.7120 - val_accuracy: 0.5495\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.6556 - accuracy: 0.6374 - val_loss: 0.7112 - val_accuracy: 0.5495\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.6554 - accuracy: 0.6374 - val_loss: 0.7102 - val_accuracy: 0.5495\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.6554 - accuracy: 0.6374 - val_loss: 0.7092 - val_accuracy: 0.5495\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.6552 - accuracy: 0.6374 - val_loss: 0.7082 - val_accuracy: 0.5495\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6552 - accuracy: 0.6374 - val_loss: 0.7080 - val_accuracy: 0.5495\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6551 - accuracy: 0.6374 - val_loss: 0.7073 - val_accuracy: 0.5495\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6551 - accuracy: 0.6374 - val_loss: 0.7066 - val_accuracy: 0.5495\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6551 - accuracy: 0.6374 - val_loss: 0.7068 - val_accuracy: 0.5495\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6550 - accuracy: 0.6374 - val_loss: 0.7069 - val_accuracy: 0.5495\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6549 - accuracy: 0.6374 - val_loss: 0.7067 - val_accuracy: 0.5495\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6549 - accuracy: 0.6374 - val_loss: 0.7065 - val_accuracy: 0.5495\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.6549 - accuracy: 0.6374 - val_loss: 0.7065 - val_accuracy: 0.5495\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6550 - accuracy: 0.6374 - val_loss: 0.7059 - val_accuracy: 0.5495\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6549 - accuracy: 0.6374 - val_loss: 0.7056 - val_accuracy: 0.5495\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6548 - accuracy: 0.6374 - val_loss: 0.7051 - val_accuracy: 0.5495\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6547 - accuracy: 0.6374 - val_loss: 0.7050 - val_accuracy: 0.5495\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.6547 - accuracy: 0.6374 - val_loss: 0.7047 - val_accuracy: 0.5495\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6547 - accuracy: 0.6374 - val_loss: 0.7045 - val_accuracy: 0.5495\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6547 - accuracy: 0.6374 - val_loss: 0.7047 - val_accuracy: 0.5495\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6549 - accuracy: 0.6374 - val_loss: 0.7039 - val_accuracy: 0.5495\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6547 - accuracy: 0.6374 - val_loss: 0.7034 - val_accuracy: 0.5495\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6547 - accuracy: 0.6374 - val_loss: 0.7037 - val_accuracy: 0.5495\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6547 - accuracy: 0.6374 - val_loss: 0.7042 - val_accuracy: 0.5495\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6548 - accuracy: 0.6374 - val_loss: 0.7042 - val_accuracy: 0.5495\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.6548 - accuracy: 0.6374 - val_loss: 0.7044 - val_accuracy: 0.5495\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.6547 - accuracy: 0.6374 - val_loss: 0.7039 - val_accuracy: 0.5495\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6546 - accuracy: 0.6374 - val_loss: 0.7036 - val_accuracy: 0.5495\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6549 - accuracy: 0.6374 - val_loss: 0.7031 - val_accuracy: 0.5495\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6547 - accuracy: 0.6374 - val_loss: 0.7030 - val_accuracy: 0.5495\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6546 - accuracy: 0.6374 - val_loss: 0.7034 - val_accuracy: 0.5495\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6548 - accuracy: 0.6374 - val_loss: 0.7026 - val_accuracy: 0.5495\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6547 - accuracy: 0.6374 - val_loss: 0.7026 - val_accuracy: 0.5495\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6546 - accuracy: 0.6374 - val_loss: 0.7028 - val_accuracy: 0.5495\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6546 - accuracy: 0.6374 - val_loss: 0.7026 - val_accuracy: 0.5495\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6547 - accuracy: 0.6374 - val_loss: 0.7028 - val_accuracy: 0.5495\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6548 - accuracy: 0.6374 - val_loss: 0.7030 - val_accuracy: 0.5495\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6546 - accuracy: 0.6374 - val_loss: 0.7031 - val_accuracy: 0.5495\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6547 - accuracy: 0.6374 - val_loss: 0.7035 - val_accuracy: 0.5495\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6546 - accuracy: 0.6374 - val_loss: 0.7033 - val_accuracy: 0.5495\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6546 - accuracy: 0.6374 - val_loss: 0.7032 - val_accuracy: 0.5495\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6546 - accuracy: 0.6374 - val_loss: 0.7033 - val_accuracy: 0.5495\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6547 - accuracy: 0.6374 - val_loss: 0.7031 - val_accuracy: 0.5495\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6548 - accuracy: 0.6374 - val_loss: 0.7030 - val_accuracy: 0.5495\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6547 - accuracy: 0.6374 - val_loss: 0.7033 - val_accuracy: 0.5495\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6547 - accuracy: 0.6374 - val_loss: 0.7033 - val_accuracy: 0.5495\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6546 - accuracy: 0.6374 - val_loss: 0.7038 - val_accuracy: 0.5495\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6546 - accuracy: 0.6374 - val_loss: 0.7038 - val_accuracy: 0.5495\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6545 - accuracy: 0.6374 - val_loss: 0.7035 - val_accuracy: 0.5495\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.6545 - accuracy: 0.6374 - val_loss: 0.7032 - val_accuracy: 0.5495\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6546 - accuracy: 0.6374 - val_loss: 0.7033 - val_accuracy: 0.5495\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6545 - accuracy: 0.6374 - val_loss: 0.7032 - val_accuracy: 0.5495\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6545 - accuracy: 0.6374 - val_loss: 0.7031 - val_accuracy: 0.5495\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6545 - accuracy: 0.6374 - val_loss: 0.7029 - val_accuracy: 0.5495\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6545 - accuracy: 0.6374 - val_loss: 0.7037 - val_accuracy: 0.5495\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6545 - accuracy: 0.6374 - val_loss: 0.7036 - val_accuracy: 0.5495\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6545 - accuracy: 0.6374 - val_loss: 0.7039 - val_accuracy: 0.5495\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6545 - accuracy: 0.6374 - val_loss: 0.7043 - val_accuracy: 0.5495\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6545 - accuracy: 0.6374 - val_loss: 0.7043 - val_accuracy: 0.5495\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6545 - accuracy: 0.6374 - val_loss: 0.7047 - val_accuracy: 0.5495\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6544 - accuracy: 0.6374 - val_loss: 0.7049 - val_accuracy: 0.5495\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6545 - accuracy: 0.6374 - val_loss: 0.7042 - val_accuracy: 0.5495\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6545 - accuracy: 0.6374 - val_loss: 0.7047 - val_accuracy: 0.5495\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6544 - accuracy: 0.6374 - val_loss: 0.7046 - val_accuracy: 0.5495\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6543 - accuracy: 0.6374 - val_loss: 0.7052 - val_accuracy: 0.5495\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6544 - accuracy: 0.6374 - val_loss: 0.7052 - val_accuracy: 0.5495\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6544 - accuracy: 0.6374 - val_loss: 0.7049 - val_accuracy: 0.5495\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6543 - accuracy: 0.6374 - val_loss: 0.7050 - val_accuracy: 0.5495\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6545 - accuracy: 0.6374 - val_loss: 0.7041 - val_accuracy: 0.5495\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6543 - accuracy: 0.6374 - val_loss: 0.7041 - val_accuracy: 0.5495\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6543 - accuracy: 0.6374 - val_loss: 0.7039 - val_accuracy: 0.5495\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6543 - accuracy: 0.6374 - val_loss: 0.7035 - val_accuracy: 0.5495\n",
            "Epoch 78/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6543 - accuracy: 0.6374 - val_loss: 0.7026 - val_accuracy: 0.5495\n",
            "Epoch 79/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6543 - accuracy: 0.6374 - val_loss: 0.7030 - val_accuracy: 0.5495\n",
            "Epoch 80/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6542 - accuracy: 0.6374 - val_loss: 0.7034 - val_accuracy: 0.5495\n",
            "Epoch 81/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6542 - accuracy: 0.6374 - val_loss: 0.7037 - val_accuracy: 0.5495\n",
            "Epoch 82/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6542 - accuracy: 0.6374 - val_loss: 0.7036 - val_accuracy: 0.5495\n",
            "Epoch 83/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6542 - accuracy: 0.6374 - val_loss: 0.7033 - val_accuracy: 0.5495\n",
            "Epoch 84/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6542 - accuracy: 0.6374 - val_loss: 0.7030 - val_accuracy: 0.5495\n",
            "Epoch 85/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6541 - accuracy: 0.6374 - val_loss: 0.7031 - val_accuracy: 0.5495\n",
            "Epoch 86/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6541 - accuracy: 0.6374 - val_loss: 0.7028 - val_accuracy: 0.5495\n",
            "Epoch 87/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6541 - accuracy: 0.6374 - val_loss: 0.7034 - val_accuracy: 0.5495\n",
            "Epoch 88/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6540 - accuracy: 0.6374 - val_loss: 0.7034 - val_accuracy: 0.5495\n",
            "Epoch 89/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6541 - accuracy: 0.6374 - val_loss: 0.7037 - val_accuracy: 0.5495\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6541 - accuracy: 0.6374 - val_loss: 0.7034 - val_accuracy: 0.5495\n",
            "Epoch 91/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6541 - accuracy: 0.6374 - val_loss: 0.7037 - val_accuracy: 0.5495\n",
            "Epoch 92/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6540 - accuracy: 0.6374 - val_loss: 0.7035 - val_accuracy: 0.5495\n",
            "Epoch 93/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6541 - accuracy: 0.6374 - val_loss: 0.7037 - val_accuracy: 0.5495\n",
            "Epoch 94/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6540 - accuracy: 0.6374 - val_loss: 0.7035 - val_accuracy: 0.5495\n",
            "Epoch 95/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6540 - accuracy: 0.6374 - val_loss: 0.7037 - val_accuracy: 0.5495\n",
            "Epoch 96/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6540 - accuracy: 0.6374 - val_loss: 0.7031 - val_accuracy: 0.5495\n",
            "Epoch 97/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6540 - accuracy: 0.6374 - val_loss: 0.7036 - val_accuracy: 0.5495\n",
            "Epoch 98/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.6541 - accuracy: 0.6374 - val_loss: 0.7031 - val_accuracy: 0.5495\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.6540 - accuracy: 0.6374 - val_loss: 0.7030 - val_accuracy: 0.5495\n",
            "Epoch 100/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.6540 - accuracy: 0.6374 - val_loss: 0.7028 - val_accuracy: 0.5495\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7c0ecb7abd60>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(x_train,y_train,batch_size = 32, epochs = 100,validation_split = 0.20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z800WPQtC4Q3",
        "outputId": "f5c2202a-564a-44a2-ec7a-121321440f06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 7ms/step - loss: 0.6426 - accuracy: 0.6579\n"
          ]
        }
      ],
      "source": [
        "results = model.evaluate(x_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOYI_3cnEbJ7",
        "outputId": "d670f4d6-985a-4553-fdda-de0ddcbd8f80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['loss', 'accuracy']\n",
            "[0.6425603032112122, 0.6578947305679321]\n"
          ]
        }
      ],
      "source": [
        "print(model.metrics_names)\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "maf7EVSiC4Os"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-H6pDbxCuQZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3XJACUjCAiG"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
