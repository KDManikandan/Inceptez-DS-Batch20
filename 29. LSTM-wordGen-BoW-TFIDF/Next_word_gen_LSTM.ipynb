{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsX50EX74fLP"
      },
      "outputs": [],
      "source": [
        "#corpus? - Set of words\n",
        "#1. Convert NL -> Latent representation (vectors) - LM (BERT) (Masked Language Modelling)\n",
        "#2. LM - Generate words (CHAT-GPT) - Generate next word (Given N words)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#[hello, work, do , perform, task]\n",
        "#Its a great morning Laxmi says ____hello____ 1. Generative models - Hallucinate, words only in training corpus"
      ],
      "metadata": {
        "id": "yRGD8aHR86P9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM , Embedding\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "HzNNBFBW92cu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#smallest unit of a paragraph - word - Tokens\n",
        "import re\n",
        "def load_doc(file):\n",
        "  #open in read mode\n",
        "  file = open(file,'r')\n",
        "  #reading text into the object\n",
        "  texts = file.read()\n",
        "  #close the connection\n",
        "  file.close()\n",
        "  return texts"
      ],
      "metadata": {
        "id": "aw93vY_R-TTW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Hello how are y-==--=ouu 0*#@&&((@) doing\"\n",
        "doc = re.sub(r'[^\\w\\s]','',text)\n",
        "doc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4IbICmNAAhMj",
        "outputId": "f46246d7-7173-4223-f04d-95f5442887bc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello how are youu 0 doing'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph = \"The birch canoe slid on the smooth planks. Glue the sheet to the dark blue background\""
      ],
      "metadata": {
        "id": "zWeD5ZyPA-LN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph.split('.')[0].split(' ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rByds1_tA-QF",
        "outputId": "8b2a062b-6ae0-4647-f298-d60a231417be"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The', 'birch', 'canoe', 'slid', 'on', 'the', 'smooth', 'planks']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#INCEPTEZ - inceptez\n",
        "def clean_doc(doc):\n",
        "  doc = re.sub(r'[^\\w\\s]','',doc)\n",
        "  #word tokenization\n",
        "  tokens = doc.split()\n",
        "  tokens = [word for word in tokens if word.isalpha()]\n",
        "  #converting to lower case\n",
        "  tokens = [word.lower() for word in tokens]\n",
        "  return tokens"
      ],
      "metadata": {
        "id": "nSJrYp5U_N8S"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_doc(paragraph)"
      ],
      "metadata": {
        "id": "TlITfzouCYjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = load_doc(\"republic_sequences.txt\")\n",
        "doc = doc[:1000000]"
      ],
      "metadata": {
        "id": "gkqn33nbCaPD"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = clean_doc(doc)"
      ],
      "metadata": {
        "id": "b-UNOJRNChxU"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fk8MSrpACht8",
        "outputId": "d2f39501-cc96-4f6c-c73f-3964ba547e2a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['introduction',\n",
              " 'and',\n",
              " 'analysis',\n",
              " 'the',\n",
              " 'republic',\n",
              " 'of',\n",
              " 'plato',\n",
              " 'is',\n",
              " 'the',\n",
              " 'longest']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train - 50 words and predict 51st word\n",
        "length = 50+1\n",
        "sequences = list()\n",
        "for i in range(length,len(tokens)):\n",
        "  #make the 50 sequencs - 0-51\n",
        "  seq = tokens[i-length:i]\n",
        "  line = \" \".join(seq)\n",
        "  sequences.append(line)"
      ],
      "metadata": {
        "id": "kBJ7FEblChrE"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The total no. of sequences are {}\".format(len(sequences)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_icW142fChnJ",
        "outputId": "d19c4bb5-ad8c-4b78-c8a0-acb702b994eb"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The total no. of sequences are 179800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Encoding sequences\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(sequences)"
      ],
      "metadata": {
        "id": "kn5Iv1gSC94R"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XY-yFIQVES7_",
        "outputId": "7144fc01-aa2b-4328-c029-f400337efa84"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'the': 1,\n",
              " 'of': 2,\n",
              " 'and': 3,\n",
              " 'in': 4,\n",
              " 'is': 5,\n",
              " 'to': 6,\n",
              " 'which': 7,\n",
              " 'a': 8,\n",
              " 'or': 9,\n",
              " 'are': 10,\n",
              " 'as': 11,\n",
              " 'be': 12,\n",
              " 'by': 13,\n",
              " 'state': 14,\n",
              " 'not': 15,\n",
              " 'have': 16,\n",
              " 'plato': 17,\n",
              " 'has': 18,\n",
              " 'justice': 19,\n",
              " 'more': 20,\n",
              " 'at': 21,\n",
              " 'an': 22,\n",
              " 'republic': 23,\n",
              " 'with': 24,\n",
              " 'but': 25,\n",
              " 'may': 26,\n",
              " 'from': 27,\n",
              " 'he': 28,\n",
              " 'all': 29,\n",
              " 'other': 30,\n",
              " 'was': 31,\n",
              " 'first': 32,\n",
              " 'into': 33,\n",
              " 'on': 34,\n",
              " 'been': 35,\n",
              " 'for': 36,\n",
              " 'his': 37,\n",
              " 'than': 38,\n",
              " 'only': 39,\n",
              " 'philosophy': 40,\n",
              " 'there': 41,\n",
              " 'life': 42,\n",
              " 'like': 43,\n",
              " 'we': 44,\n",
              " 'this': 45,\n",
              " 'it': 46,\n",
              " 'one': 47,\n",
              " 'them': 48,\n",
              " 'truth': 49,\n",
              " 'that': 50,\n",
              " 'work': 51,\n",
              " 'no': 52,\n",
              " 'cp': 53,\n",
              " 'books': 54,\n",
              " 'who': 55,\n",
              " 'him': 56,\n",
              " 'great': 57,\n",
              " 'same': 58,\n",
              " 'world': 59,\n",
              " 'well': 60,\n",
              " 'had': 61,\n",
              " 'mind': 62,\n",
              " 'own': 63,\n",
              " 'some': 64,\n",
              " 'whole': 65,\n",
              " 'idea': 66,\n",
              " 'about': 67,\n",
              " 'higher': 68,\n",
              " 'writings': 69,\n",
              " 'second': 70,\n",
              " 'argument': 71,\n",
              " 'they': 72,\n",
              " 'ideas': 73,\n",
              " 'such': 74,\n",
              " 'any': 75,\n",
              " 'would': 76,\n",
              " 'knowledge': 77,\n",
              " 'most': 78,\n",
              " 'design': 79,\n",
              " 'good': 80,\n",
              " 'another': 81,\n",
              " 'nature': 82,\n",
              " 'poetry': 83,\n",
              " 'human': 84,\n",
              " 'writer': 85,\n",
              " 'whether': 86,\n",
              " 'ideal': 87,\n",
              " 'greatest': 88,\n",
              " 'himself': 89,\n",
              " 'made': 90,\n",
              " 'ancient': 91,\n",
              " 'many': 92,\n",
              " 'upon': 93,\n",
              " 'division': 94,\n",
              " 'aristotle': 95,\n",
              " 'book': 96,\n",
              " 'what': 97,\n",
              " 'perhaps': 98,\n",
              " 'hellenic': 99,\n",
              " 'two': 100,\n",
              " 'education': 101,\n",
              " 'unity': 102,\n",
              " 'when': 103,\n",
              " 'their': 104,\n",
              " 'after': 105,\n",
              " 'individual': 106,\n",
              " 'now': 107,\n",
              " 'general': 108,\n",
              " 'time': 109,\n",
              " 'modern': 110,\n",
              " 'laws': 111,\n",
              " 'works': 112,\n",
              " 'out': 113,\n",
              " 'thoughts': 114,\n",
              " 'new': 115,\n",
              " 'old': 116,\n",
              " 'politics': 117,\n",
              " 'dialogues': 118,\n",
              " 'both': 119,\n",
              " 'science': 120,\n",
              " 'thought': 121,\n",
              " 'socrates': 122,\n",
              " 'law': 123,\n",
              " 'between': 124,\n",
              " 'elements': 125,\n",
              " 'found': 126,\n",
              " 'were': 127,\n",
              " 'probably': 128,\n",
              " 'writers': 129,\n",
              " 'third': 130,\n",
              " 'history': 131,\n",
              " 'because': 132,\n",
              " 'imaginary': 133,\n",
              " 'over': 134,\n",
              " 'order': 135,\n",
              " 'original': 136,\n",
              " 'philosophers': 137,\n",
              " 'too': 138,\n",
              " 'literature': 139,\n",
              " 'man': 140,\n",
              " 'do': 141,\n",
              " 'question': 142,\n",
              " 'kingdom': 143,\n",
              " 'through': 144,\n",
              " 'different': 145,\n",
              " 'platonic': 146,\n",
              " 'therefore': 147,\n",
              " 'under': 148,\n",
              " 'form': 149,\n",
              " 'ever': 150,\n",
              " 'later': 151,\n",
              " 'art': 152,\n",
              " 'perfection': 153,\n",
              " 'age': 154,\n",
              " 'nor': 155,\n",
              " 'speculation': 156,\n",
              " 'v': 157,\n",
              " 'conceived': 158,\n",
              " 'although': 159,\n",
              " 'neither': 160,\n",
              " 'always': 161,\n",
              " 'yet': 162,\n",
              " 'genius': 163,\n",
              " 'logic': 164,\n",
              " 'so': 165,\n",
              " 'based': 166,\n",
              " 'also': 167,\n",
              " 'necessary': 168,\n",
              " 'these': 169,\n",
              " 'words': 170,\n",
              " 'rep': 171,\n",
              " 'up': 172,\n",
              " 'still': 173,\n",
              " 'must': 174,\n",
              " 'part': 175,\n",
              " 'political': 176,\n",
              " 'critias': 177,\n",
              " 'fiction': 178,\n",
              " 'said': 179,\n",
              " 'subject': 180,\n",
              " 'again': 181,\n",
              " 'god': 182,\n",
              " 'states': 183,\n",
              " 'common': 184,\n",
              " 'greek': 185,\n",
              " 'reign': 186,\n",
              " 'then': 187,\n",
              " 'morality': 188,\n",
              " 'having': 189,\n",
              " 'hardly': 190,\n",
              " 'much': 191,\n",
              " 'i': 192,\n",
              " 'according': 193,\n",
              " 'answer': 194,\n",
              " 'generally': 195,\n",
              " 'phaedrus': 196,\n",
              " 'plan': 197,\n",
              " 'times': 198,\n",
              " 'occur': 199,\n",
              " 'us': 200,\n",
              " 'visible': 201,\n",
              " 'sun': 202,\n",
              " 'years': 203,\n",
              " 'writing': 204,\n",
              " 'introduction': 205,\n",
              " 'institutions': 206,\n",
              " 'drawn': 207,\n",
              " 'dialogue': 208,\n",
              " 'view': 209,\n",
              " 'contains': 210,\n",
              " 'those': 211,\n",
              " 'nowhere': 212,\n",
              " 'greater': 213,\n",
              " 'dramatic': 214,\n",
              " 'reaches': 215,\n",
              " 'highest': 216,\n",
              " 'especially': 217,\n",
              " 'thinkers': 218,\n",
              " 'among': 219,\n",
              " 'bacon': 220,\n",
              " 'method': 221,\n",
              " 'outline': 222,\n",
              " 'content': 223,\n",
              " 'abstraction': 224,\n",
              " 'realized': 225,\n",
              " 'seen': 226,\n",
              " 'thinker': 227,\n",
              " 'future': 228,\n",
              " 'principles': 229,\n",
              " 'definition': 230,\n",
              " 'circle': 231,\n",
              " 'thing': 232,\n",
              " 'conditions': 233,\n",
              " 'logical': 234,\n",
              " 'truths': 235,\n",
              " 'ff': 236,\n",
              " 'does': 237,\n",
              " 'veiled': 238,\n",
              " 'imagines': 239,\n",
              " 'existence': 240,\n",
              " 'discovered': 241,\n",
              " 'athens': 242,\n",
              " 'fragment': 243,\n",
              " 'tale': 244,\n",
              " 'inspired': 245,\n",
              " 'early': 246,\n",
              " 'athenians': 247,\n",
              " 'supposed': 248,\n",
              " 'homer': 249,\n",
              " 'struggle': 250,\n",
              " 'tim': 251,\n",
              " 'hellas': 252,\n",
              " 'timaeus': 253,\n",
              " 'itself': 254,\n",
              " 'treated': 255,\n",
              " 'can': 256,\n",
              " 'growth': 257,\n",
              " 'speech': 258,\n",
              " 'every': 259,\n",
              " 'regarded': 260,\n",
              " 'sir': 261,\n",
              " 'numerous': 262,\n",
              " 'framed': 263,\n",
              " 'model': 264,\n",
              " 'our': 265,\n",
              " 'authors': 266,\n",
              " 'brought': 267,\n",
              " 'influence': 268,\n",
              " 'revelation': 269,\n",
              " 'church': 270,\n",
              " 'real': 271,\n",
              " 'symp': 272,\n",
              " 'ages': 273,\n",
              " 'reflected': 274,\n",
              " 'just': 275,\n",
              " 'reduced': 276,\n",
              " 'glaucon': 277,\n",
              " 'adeimantus': 278,\n",
              " 'reappears': 279,\n",
              " 'length': 280,\n",
              " 'constructed': 281,\n",
              " 'rulers': 282,\n",
              " 'religion': 283,\n",
              " 'harmony': 284,\n",
              " 'thus': 285,\n",
              " 'led': 286,\n",
              " 'conception': 287,\n",
              " 'anything': 288,\n",
              " 'kings': 289,\n",
              " 'youth': 290,\n",
              " 'democracy': 291,\n",
              " 'tyranny': 292,\n",
              " 'regular': 293,\n",
              " 'facts': 294,\n",
              " 'come': 295,\n",
              " 'end': 296,\n",
              " 'earlier': 297,\n",
              " 'conclusion': 298,\n",
              " 'poets': 299,\n",
              " 'similar': 300,\n",
              " 'divisions': 301,\n",
              " 'ii': 302,\n",
              " 'beginning': 303,\n",
              " 'containing': 304,\n",
              " 'notions': 305,\n",
              " 'without': 306,\n",
              " 'occupied': 307,\n",
              " 'construction': 308,\n",
              " 'fifth': 309,\n",
              " 'sixth': 310,\n",
              " 'seventh': 311,\n",
              " 'rather': 312,\n",
              " 'enquiry': 313,\n",
              " 'takes': 314,\n",
              " 'virtues': 315,\n",
              " 'perversions': 316,\n",
              " 'principle': 317,\n",
              " 'finally': 318,\n",
              " 'determined': 319,\n",
              " 'imperfect': 320,\n",
              " 'light': 321,\n",
              " 'heavens': 322,\n",
              " 'few': 323,\n",
              " 'laid': 324,\n",
              " 'single': 325,\n",
              " 'being': 326,\n",
              " 'composed': 327,\n",
              " 'element': 328,\n",
              " 'hand': 329,\n",
              " 'able': 330,\n",
              " 'language': 331,\n",
              " 'hands': 332,\n",
              " 'degree': 333,\n",
              " 'concerning': 334,\n",
              " 'date': 335,\n",
              " 'principal': 336,\n",
              " 'embodiment': 337,\n",
              " 'soul': 338,\n",
              " 'body': 339,\n",
              " 'fair': 340,\n",
              " 'external': 341,\n",
              " 'building': 342,\n",
              " 'use': 343,\n",
              " 'dismissed': 344,\n",
              " 'outward': 345,\n",
              " 'need': 346,\n",
              " 'naturally': 347,\n",
              " 'prose': 348,\n",
              " 'least': 349,\n",
              " 'heaven': 350,\n",
              " 'discuss': 351,\n",
              " 'metaphysics': 352,\n",
              " 'athenian': 353,\n",
              " 'respecting': 354,\n",
              " 'clearly': 355,\n",
              " 'symposium': 356,\n",
              " 'protagoras': 357,\n",
              " 'excellence': 358,\n",
              " 'largeness': 359,\n",
              " 'style': 360,\n",
              " 'shows': 361,\n",
              " 'equal': 362,\n",
              " 'deeper': 363,\n",
              " 'irony': 364,\n",
              " 'wealth': 365,\n",
              " 'humour': 366,\n",
              " 'imagery': 367,\n",
              " 'power': 368,\n",
              " 'attempt': 369,\n",
              " 'interweave': 370,\n",
              " 'connect': 371,\n",
              " 'centre': 372,\n",
              " 'around': 373,\n",
              " 'grouped': 374,\n",
              " 'here': 375,\n",
              " 'point': 376,\n",
              " 'vi': 377,\n",
              " 'vii': 378,\n",
              " 'attained': 379,\n",
              " 'greeks': 380,\n",
              " 'moderns': 381,\n",
              " 'distinguished': 382,\n",
              " 'bare': 383,\n",
              " 'substance': 384,\n",
              " 'metaphysical': 385,\n",
              " 'whom': 386,\n",
              " 'germs': 387,\n",
              " 'contained': 388,\n",
              " 'sciences': 389,\n",
              " 'psychology': 390,\n",
              " 'supplied': 391,\n",
              " 'instruments': 392,\n",
              " 'afterages': 393,\n",
              " 'analyses': 394,\n",
              " 'contradiction': 395,\n",
              " 'fallacy': 396,\n",
              " 'arguing': 397,\n",
              " 'distinction': 398,\n",
              " 'essence': 399,\n",
              " 'accidents': 400,\n",
              " 'notion': 401,\n",
              " 'means': 402,\n",
              " 'ends': 403,\n",
              " 'causes': 404,\n",
              " 'rational': 405,\n",
              " 'concupiscent': 406,\n",
              " 'irascible': 407,\n",
              " 'pleasures': 408,\n",
              " 'desires': 409,\n",
              " 'unnecessary': 410,\n",
              " 'forms': 411,\n",
              " 'invented': 412,\n",
              " 'apt': 413,\n",
              " 'lose': 414,\n",
              " 'sight': 415,\n",
              " 'difference': 416,\n",
              " 'things': 417,\n",
              " 'strenuously': 418,\n",
              " 'insisted': 419,\n",
              " 'polit': 420,\n",
              " 'cratyl': 421,\n",
              " 'avoided': 422,\n",
              " 'confusion': 423,\n",
              " 'eg': 424,\n",
              " 'bind': 425,\n",
              " 'formulae': 426,\n",
              " 'contemplate': 427,\n",
              " 'very': 428,\n",
              " 'unlike': 429,\n",
              " 'doctrine': 430,\n",
              " 'syllogism': 431,\n",
              " 'claims': 432,\n",
              " 'soph': 433,\n",
              " 'elenchi': 434,\n",
              " 'forget': 435,\n",
              " 'larger': 436,\n",
              " 'included': 437,\n",
              " 'physical': 438,\n",
              " 'given': 439,\n",
              " 'birth': 440,\n",
              " 'worldfamous': 441,\n",
              " 'importance': 442,\n",
              " 'troy': 443,\n",
              " 'legend': 444,\n",
              " 'arthur': 445,\n",
              " 'fact': 446,\n",
              " 'navigators': 447,\n",
              " 'sixteenth': 448,\n",
              " 'century': 449,\n",
              " 'mythical': 450,\n",
              " 'wars': 451,\n",
              " 'against': 452,\n",
              " 'island': 453,\n",
              " 'atlantis': 454,\n",
              " 'founded': 455,\n",
              " 'unfinished': 456,\n",
              " 'poem': 457,\n",
              " 'solon': 458,\n",
              " 'stood': 459,\n",
              " 'relation': 460,\n",
              " 'logographers': 461,\n",
              " 'poems': 462,\n",
              " 'told': 463,\n",
              " 'liberty': 464,\n",
              " 'c': 465,\n",
              " 'intended': 466,\n",
              " 'represent': 467,\n",
              " 'conflict': 468,\n",
              " 'persia': 469,\n",
              " 'judge': 470,\n",
              " 'noble': 471,\n",
              " 'commencement': 472,\n",
              " 'manner': 473,\n",
              " 'high': 474,\n",
              " 'guess': 475,\n",
              " 'why': 476,\n",
              " 'abandoned': 477,\n",
              " 'became': 478,\n",
              " 'sensible': 479,\n",
              " 'incongruity': 480,\n",
              " 'fictitious': 481,\n",
              " 'lost': 482,\n",
              " 'interest': 483,\n",
              " 'advancing': 484,\n",
              " 'forbade': 485,\n",
              " 'completion': 486,\n",
              " 'please': 487,\n",
              " 'ourselves': 488,\n",
              " 'fancy': 489,\n",
              " 'narrative': 490,\n",
              " 'finished': 491,\n",
              " 'should': 492,\n",
              " 'sympathising': 493,\n",
              " 'independence': 494,\n",
              " 'iii': 495,\n",
              " 'singing': 496,\n",
              " 'hymn': 497,\n",
              " 'triumph': 498,\n",
              " 'marathon': 499,\n",
              " 'salamis': 500,\n",
              " 'making': 501,\n",
              " 'reflection': 502,\n",
              " 'herodotus': 503,\n",
              " 'where': 504,\n",
              " 'contemplates': 505,\n",
              " 'empire': 506,\n",
              " 'how': 507,\n",
              " 'brave': 508,\n",
              " 'freedom': 509,\n",
              " 'far': 510,\n",
              " 'exceed': 511,\n",
              " 'greatness': 512,\n",
              " 'attributing': 513,\n",
              " 'victory': 514,\n",
              " 'favor': 515,\n",
              " 'apollo': 516,\n",
              " 'athene': 517,\n",
              " 'introd': 518,\n",
              " 'captain': 519,\n",
              " 'arhchegoz': 520,\n",
              " 'leader': 521,\n",
              " 'goodly': 522,\n",
              " 'band': 523,\n",
              " 'followers': 524,\n",
              " 'ciceros': 525,\n",
              " 'de': 526,\n",
              " 'republica': 527,\n",
              " 'st': 528,\n",
              " 'augustines': 529,\n",
              " 'city': 530,\n",
              " 'utopia': 531,\n",
              " 'thomas': 532,\n",
              " 'extent': 533,\n",
              " 'aristotelian': 534,\n",
              " 'school': 535,\n",
              " 'indebted': 536,\n",
              " 'little': 537,\n",
              " 'recognised': 538,\n",
              " 'recognition': 539,\n",
              " 'conscious': 540,\n",
              " 'remain': 541,\n",
              " 'undetected': 542,\n",
              " 'english': 543,\n",
              " 'affinities': 544,\n",
              " 'traced': 545,\n",
              " 'cambridge': 546,\n",
              " 'platonists': 547,\n",
              " 'berkeley': 548,\n",
              " 'coleridge': 549,\n",
              " 'experience': 550,\n",
              " 'bears': 551,\n",
              " 'witness': 552,\n",
              " 'herself': 553,\n",
              " 'conviction': 554,\n",
              " 'generation': 555,\n",
              " 'enthusiastically': 556,\n",
              " 'asserted': 557,\n",
              " 'gaining': 558,\n",
              " 'ground': 559,\n",
              " 'renaissance': 560,\n",
              " 'treatise': 561,\n",
              " 'milton': 562,\n",
              " 'locke': 563,\n",
              " 'rousseau': 564,\n",
              " 'jean': 565,\n",
              " 'paul': 566,\n",
              " 'goethe': 567,\n",
              " 'legitimate': 568,\n",
              " 'descendants': 569,\n",
              " 'dante': 570,\n",
              " 'bunyan': 571,\n",
              " 'profoundly': 572,\n",
              " 'impressed': 573,\n",
              " 'exercised': 574,\n",
              " 'theology': 575,\n",
              " 'revival': 576,\n",
              " 'even': 577,\n",
              " 'fragments': 578,\n",
              " 'repeated': 579,\n",
              " 'secondhand': 580,\n",
              " 'd': 581,\n",
              " 'ravished': 582,\n",
              " 'hearts': 583,\n",
              " 'men': 584,\n",
              " 'father': 585,\n",
              " 'idealism': 586,\n",
              " 'latest': 587,\n",
              " 'conceptions': 588,\n",
              " 'statesmen': 589,\n",
              " 'equality': 590,\n",
              " 'sexes': 591,\n",
              " 'anticipated': 592,\n",
              " 'dream': 593,\n",
              " 'search': 594,\n",
              " 'hinted': 595,\n",
              " 'cephalus': 596,\n",
              " 'blameless': 597,\n",
              " 'discussed': 598,\n",
              " 'basis': 599,\n",
              " 'proverbial': 600,\n",
              " 'polemarchus': 601,\n",
              " 'caricatured': 602,\n",
              " 'thrasymachus': 603,\n",
              " 'partially': 604,\n",
              " 'explained': 605,\n",
              " 'become': 606,\n",
              " 'invisible': 607,\n",
              " 'care': 608,\n",
              " 'providing': 609,\n",
              " 'improved': 610,\n",
              " 'simplicity': 611,\n",
              " 'music': 612,\n",
              " 'gymnastic': 613,\n",
              " 'manlier': 614,\n",
              " 'strain': 615,\n",
              " 'calls': 616,\n",
              " 'marrying': 617,\n",
              " 'giving': 618,\n",
              " 'marriage': 619,\n",
              " 'intellectual': 620,\n",
              " 'moral': 621,\n",
              " 'religious': 622,\n",
              " 'quickly': 623,\n",
              " 'degenerates': 624,\n",
              " 'perfect': 625,\n",
              " 'succeeds': 626,\n",
              " 'government': 627,\n",
              " 'soldier': 628,\n",
              " 'lover': 629,\n",
              " 'honour': 630,\n",
              " 'declining': 631,\n",
              " 'resemblance': 632,\n",
              " 'actual': 633,\n",
              " 'wheel': 634,\n",
              " 'full': 635,\n",
              " 'begin': 636,\n",
              " 'period': 637,\n",
              " 'passed': 638,\n",
              " 'best': 639,\n",
              " 'worst': 640,\n",
              " 'changed': 641,\n",
              " 'quarrel': 642,\n",
              " 'lightly': 643,\n",
              " 'resumed': 644,\n",
              " 'fought': 645,\n",
              " 'imitation': 646,\n",
              " 'thrice': 647,\n",
              " 'removed': 648,\n",
              " 'condemned': 649,\n",
              " 'imitator': 650,\n",
              " 'sent': 651,\n",
              " 'banishment': 652,\n",
              " 'along': 653,\n",
              " 'supplemented': 654,\n",
              " 'gc': 655,\n",
              " 'lewis': 656,\n",
              " 'classical': 657,\n",
              " 'museum': 658,\n",
              " 'vol': 659,\n",
              " 'p': 660,\n",
              " 'natural': 661,\n",
              " 'five': 662,\n",
              " 'number': 663,\n",
              " 'half': 664,\n",
              " 'down': 665,\n",
              " 'paragraph': 666,\n",
              " 'admired': 667,\n",
              " 'introductory': 668,\n",
              " 'refutation': 669,\n",
              " 'popular': 670,\n",
              " 'sophistical': 671,\n",
              " 'concluding': 672,\n",
              " 'arriving': 673,\n",
              " 'definite': 674,\n",
              " 'result': 675,\n",
              " 'appended': 676,\n",
              " 'restatement': 677,\n",
              " 'opinion': 678,\n",
              " 'demanded': 679,\n",
              " 'stripped': 680,\n",
              " 'appearances': 681,\n",
              " 'includes': 682,\n",
              " 'remainder': 683,\n",
              " 'fourth': 684,\n",
              " 'mainly': 685,\n",
              " 'consists': 686,\n",
              " 'communism': 687,\n",
              " 'ruled': 688,\n",
              " 'contemplation': 689,\n",
              " 'place': 690,\n",
              " 'social': 691,\n",
              " 'eighth': 692,\n",
              " 'ninth': 693,\n",
              " 'individuals': 694,\n",
              " 'correspond': 695,\n",
              " 'reviewed': 696,\n",
              " 'succession': 697,\n",
              " 'pleasure': 698,\n",
              " 'further': 699,\n",
              " 'analysed': 700,\n",
              " 'tenth': 701,\n",
              " 'relations': 702,\n",
              " 'happiness': 703,\n",
              " 'citizens': 704,\n",
              " 'assured': 705,\n",
              " 'crowned': 706,\n",
              " 'vision': 707,\n",
              " 'parts': 708,\n",
              " 'adopted': 709,\n",
              " 'iv': 710,\n",
              " 'description': 711,\n",
              " 'accordance': 712,\n",
              " 'while': 713,\n",
              " 'x': 714,\n",
              " 'transformed': 715,\n",
              " 'governments': 716,\n",
              " 'points': 717,\n",
              " 'really': 718,\n",
              " 'opposed': 719,\n",
              " 'opposition': 720,\n",
              " 'see': 721,\n",
              " 'breaks': 722,\n",
              " 'regularity': 723,\n",
              " 'temple': 724,\n",
              " 'last': 725,\n",
              " 'fades': 726,\n",
              " 'away': 727,\n",
              " 'imperfection': 728,\n",
              " 'structure': 729,\n",
              " 'arises': 730,\n",
              " 'enlargement': 731,\n",
              " 'reconcilement': 732,\n",
              " 'struggling': 733,\n",
              " 'together': 734,\n",
              " 'composition': 735,\n",
              " 'questions': 736,\n",
              " 'iliad': 737,\n",
              " 'odyssey': 738,\n",
              " 'worth': 739,\n",
              " 'asking': 740,\n",
              " 'cannot': 741,\n",
              " 'distinct': 742,\n",
              " 'mode': 743,\n",
              " 'publication': 744,\n",
              " 'author': 745,\n",
              " 'less': 746,\n",
              " 'scruple': 747,\n",
              " 'altering': 748,\n",
              " 'adding': 749,\n",
              " 'known': 750,\n",
              " 'friends': 751,\n",
              " 'absurdity': 752,\n",
              " 'supposing': 753,\n",
              " 'labours': 754,\n",
              " 'aside': 755,\n",
              " 'turned': 756,\n",
              " 'interruptions': 757,\n",
              " 'likely': 758,\n",
              " 'case': 759,\n",
              " 'long': 760,\n",
              " 'short': 761,\n",
              " 'attempts': 762,\n",
              " 'determine': 763,\n",
              " 'chronological': 764,\n",
              " 'internal': 765,\n",
              " 'evidence': 766,\n",
              " 'uncertainty': 767,\n",
              " 'disturbing': 768,\n",
              " 'admitted': 769,\n",
              " 'affect': 770,\n",
              " 'longer': 771,\n",
              " 'shorter': 772,\n",
              " 'ones': 773,\n",
              " 'seeming': 774,\n",
              " 'discrepancies': 775,\n",
              " 'arise': 776,\n",
              " 'discordant': 777,\n",
              " 'philosopher': 778,\n",
              " 'attempted': 779,\n",
              " 'unite': 780,\n",
              " 'recognise': 781,\n",
              " 'inconsistency': 782,\n",
              " 'obvious': 783,\n",
              " 'judgment': 784,\n",
              " 'anticipate': 785,\n",
              " 'themselves': 786,\n",
              " 'perceive': 787,\n",
              " 'want': 788,\n",
              " 'connexion': 789,\n",
              " 'gaps': 790,\n",
              " 'systems': 791,\n",
              " 'enough': 792,\n",
              " 'beginnings': 793,\n",
              " 'amid': 794,\n",
              " 'efforts': 795,\n",
              " 'inconsistencies': 796,\n",
              " 'paths': 797,\n",
              " 'worn': 798,\n",
              " 'meaning': 799,\n",
              " 'precisely': 800,\n",
              " 'defined': 801,\n",
              " 'consistency': 802,\n",
              " 'creations': 803,\n",
              " 'wanting': 804,\n",
              " 'tried': 805,\n",
              " 'test': 806,\n",
              " 'several': 807,\n",
              " 'appear': 808,\n",
              " 'defective': 809,\n",
              " 'deficiency': 810,\n",
              " 'proof': 811,\n",
              " 'supposition': 812,\n",
              " 'written': 813,\n",
              " 'uninterruptedly': 814,\n",
              " 'continuous': 815,\n",
              " 'effort': 816,\n",
              " 'confirmed': 817,\n",
              " 'references': 818,\n",
              " 'title': 819,\n",
              " 'quoted': 820,\n",
              " 'either': 821,\n",
              " 'antiquity': 822,\n",
              " 'titles': 823,\n",
              " 'assumed': 824,\n",
              " 'morgenstern': 825,\n",
              " 'others': 826,\n",
              " 'asked': 827,\n",
              " 'professed': 828,\n",
              " 'aim': 829,\n",
              " 'blend': 830,\n",
              " 'faces': 831,\n",
              " 'society': 832,\n",
              " 'hegelian': 833,\n",
              " 'phraseology': 834,\n",
              " 'reality': 835,\n",
              " 'described': 836,\n",
              " 'christian': 837,\n",
              " 'within': 838,\n",
              " 'developes': 839,\n",
              " 'house': 840,\n",
              " 'eternal': 841,\n",
              " 'proportions': 842,\n",
              " 'earthly': 843,\n",
              " 'image': 844,\n",
              " 'warp': 845,\n",
              " 'woof': 846,\n",
              " 'run': 847,\n",
              " 'texture': 848,\n",
              " 'constitution': 849,\n",
              " 'completed': 850,\n",
              " 'names': 851,\n",
              " 'throughout': 852,\n",
              " 'inner': 853,\n",
              " 'rewards': 854,\n",
              " 'punishments': 855,\n",
              " 'honesty': 856,\n",
              " 'buying': 857,\n",
              " 'selling': 858,\n",
              " 'shadow': 859,\n",
              " 'motions': 860,\n",
              " 'heavenly': 861,\n",
              " 'bodies': 862,\n",
              " 'ethical': 863,\n",
              " 'side': 864,\n",
              " 'chiefly': 865,\n",
              " 'hypotheses': 866,\n",
              " 'indications': 867,\n",
              " 'however': 868,\n",
              " 'stage': 869,\n",
              " 'criticism': 870,\n",
              " 'referred': 871,\n",
              " 'indeed': 872,\n",
              " 'remains': 873,\n",
              " 'often': 874,\n",
              " 'large': 875,\n",
              " 'comprehended': 876,\n",
              " 'grows': 877,\n",
              " 'act': 878,\n",
              " 'worked': 879,\n",
              " 'before': 880,\n",
              " 'begins': 881,\n",
              " 'reader': 882,\n",
              " 'seeks': 883,\n",
              " 'find': 884,\n",
              " 'necessarily': 885,\n",
              " 'seize': 886,\n",
              " 'vaguest': 887,\n",
              " 'stallbaum': 888,\n",
              " 'dissatisfied': 889,\n",
              " 'ordinary': 890,\n",
              " 'explanations': 891,\n",
              " 'true': 892,\n",
              " 'representation': 893,\n",
              " 'perfected': 894,\n",
              " 'governed': 895,\n",
              " 'descriptions': 896,\n",
              " 'express': 897,\n",
              " 'speak': 898,\n",
              " 'designs': 899,\n",
              " 'excluded': 900,\n",
              " 'association': 901,\n",
              " 'interfere': 902,\n",
              " 'purpose': 903,\n",
              " 'kind': 904,\n",
              " 'sought': 905,\n",
              " 'plastic': 906,\n",
              " 'arts': 907,\n",
              " 'problem': 908,\n",
              " 'relatively': 909,\n",
              " 'subjectmatter': 910,\n",
              " 'intention': 911,\n",
              " 'intelligible': 912,\n",
              " 'better': 913,\n",
              " 'once': 914,\n",
              " 'vehicle': 915,\n",
              " 'three': 916,\n",
              " 'four': 917,\n",
              " 'platos': 918,\n",
              " 'represented': 919,\n",
              " 'jewish': 920,\n",
              " 'prophets': 921,\n",
              " 'messiah': 922,\n",
              " 'day': 923,\n",
              " 'lord': 924,\n",
              " 'suffering': 925,\n",
              " 'servant': 926,\n",
              " 'people': 927,\n",
              " 'righteousness': 928,\n",
              " 'healing': 929,\n",
              " 'wings': 930,\n",
              " 'convey': 931,\n",
              " 'spiritual': 932,\n",
              " 'ideals': 933,\n",
              " 'reveals': 934,\n",
              " 'divine': 935,\n",
              " 'continuing': 936,\n",
              " 'sophists': 937,\n",
              " 'tyrants': 938,\n",
              " 'false': 939,\n",
              " 'teachers': 940,\n",
              " 'evil': 941,\n",
              " 'mankind': 942,\n",
              " 'exists': 943,\n",
              " 'earth': 944,\n",
              " 'pattern': 945,\n",
              " 'rule': 946,\n",
              " 'creation': 947,\n",
              " 'clouds': 948,\n",
              " 'pierces': 949,\n",
              " 'shade': 950,\n",
              " 'dark': 951,\n",
              " 'veil': 952,\n",
              " 'allowable': 953,\n",
              " 'philosophical': 954,\n",
              " 'imagination': 955,\n",
              " 'plane': 956,\n",
              " 'easily': 957,\n",
              " 'passes': 958,\n",
              " 'myths': 959,\n",
              " 'fancies': 960,\n",
              " 'figures': 961,\n",
              " 'ought': 962,\n",
              " 'judged': 963,\n",
              " 'rules': 964,\n",
              " 'probabilities': 965,\n",
              " 'fashioning': 966,\n",
              " 'artistic': 967,\n",
              " 'take': 968,\n",
              " 'possession': 969,\n",
              " 'practicable': 970,\n",
              " 'inward': 971,\n",
              " 'came': 972,\n",
              " 'practicability': 973,\n",
              " 'nothing': 974,\n",
              " 'attains': 975,\n",
              " 'truly': 976,\n",
              " 'bear': 977,\n",
              " 'marks': 978,\n",
              " 'framework': 979,\n",
              " 'dialectic': 980,\n",
              " 'organisation': 981,\n",
              " 'type': 982,\n",
              " 'spirit': 983,\n",
              " 'pursued': 984,\n",
              " 'spectator': 985,\n",
              " 'summit': 986,\n",
              " 'fail': 987,\n",
              " 'satisfy': 988,\n",
              " 'requirements': 989,\n",
              " 'important': 990,\n",
              " 'portions': 991,\n",
              " 'minor': 992,\n",
              " 'raised': 993,\n",
              " 'boeckh': 994,\n",
              " 'conversation': 995,\n",
              " 'held': 996,\n",
              " 'year': 997,\n",
              " 'bc': 998,\n",
              " 'proposed': 999,\n",
              " 'will': 1000,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.word_index)+1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2wKnTsIEy_G",
        "outputId": "bcf9ca49-df4f-4bd5-fb2b-dd9df41d7a39"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1026"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(tokenizer.word_index)+1"
      ],
      "metadata": {
        "id": "eIf-VfI-C91Z"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = tokenizer.texts_to_sequences(sequences)"
      ],
      "metadata": {
        "id": "8WcDPFqrC9yh"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences[0]"
      ],
      "metadata": {
        "id": "rcFv7wbLC9v6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = np.array(sequences)\n",
        "X,y = sequences[:,:-1],sequences[:,-1]\n",
        "y = to_categorical(y, num_classes = vocab_size)\n",
        "seq_length = X.shape[1]"
      ],
      "metadata": {
        "id": "Dx8rjoHVC9tU"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model= Sequential()"
      ],
      "metadata": {
        "id": "CcB07BnNC9qc"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Embedding(vocab_size, 50, input_length = seq_length))\n",
        "model.add(LSTM(100, return_sequences = True))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(vocab_size,activation='softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QN_a3HHyC9nV",
        "outputId": "9299e0f4-3096-4335-cb1c-76e2c18f6884"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 50, 50)            51300     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 50, 100)           60400     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 100)               80400     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1026)              103626    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 295,726\n",
            "Trainable params: 295,726\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam',metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "7L5Q-5PNC9ku"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X,y,batch_size = 128, epochs = 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad7wWYOpC9h2",
        "outputId": "d4fe23dd-157c-4bea-901f-6de7dcf50de1"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1405/1405 [==============================] - 49s 28ms/step - loss: 4.9398 - accuracy: 0.1650\n",
            "Epoch 2/10\n",
            "1405/1405 [==============================] - 16s 11ms/step - loss: 3.8321 - accuracy: 0.2647\n",
            "Epoch 3/10\n",
            "1405/1405 [==============================] - 16s 12ms/step - loss: 3.0103 - accuracy: 0.3717\n",
            "Epoch 4/10\n",
            "1405/1405 [==============================] - 14s 10ms/step - loss: 2.2657 - accuracy: 0.5225\n",
            "Epoch 5/10\n",
            "1405/1405 [==============================] - 14s 10ms/step - loss: 1.6212 - accuracy: 0.6893\n",
            "Epoch 6/10\n",
            "1405/1405 [==============================] - 14s 10ms/step - loss: 1.1604 - accuracy: 0.8145\n",
            "Epoch 7/10\n",
            "1405/1405 [==============================] - 15s 10ms/step - loss: 0.8374 - accuracy: 0.8903\n",
            "Epoch 8/10\n",
            "1405/1405 [==============================] - 15s 11ms/step - loss: 0.6325 - accuracy: 0.9271\n",
            "Epoch 9/10\n",
            "1405/1405 [==============================] - 16s 11ms/step - loss: 0.5038 - accuracy: 0.9434\n",
            "Epoch 10/10\n",
            "1405/1405 [==============================] - 14s 10ms/step - loss: 0.4188 - accuracy: 0.9501\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x78b49ef9ba90>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "76KOS2DdJenG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l20CgdiLJesq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ":50 - 51st output\n",
        ":5  - 6th\n",
        "#padding\n",
        "000000...44th -----  -> Pre\n",
        "----- : 000000...50th -> Post"
      ],
      "metadata": {
        "id": "43X__jOMHxtC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HlhIjiDwKfZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x in y_ANNprediction:\n",
        "    y_ANN_prediction_classes.append(np.argmax(x))\n",
        "\n",
        "#Conver the list back to a numpy arrach\n",
        "y_ANN_prediction_classes_arr = np.array(y_ANN_prediction_classes)"
      ],
      "metadata": {
        "id": "FuYumsY1Kfek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_seq(model, tokenizer, seq_length,in_text, n_words):\n",
        "  for _ in range(n_words):\n",
        "    encoded = tokenizer.texts_to_sequences([in_text])\n",
        "    encoded = keras.preprocessing.sequence.pad_sequences(encoded, maxlen = seq_length, truncating = 'pre')\n",
        "    y_prediction_classes = []\n",
        "    yhat_ = model.predict(encoded,verbose = 0)\n",
        "    for x in yhat_:\n",
        "      y_prediction_classes.append(np.argmax(x))\n",
        "    yhat = np.array(y_prediction_classes)\n",
        "    out_word = ''\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "      if index == yhat:\n",
        "        out_word = word\n",
        "        break\n",
        "    in_text+=\" \"+out_word\n",
        "  return in_text"
      ],
      "metadata": {
        "id": "6EqTuRj9C9fR"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "in_text = \"Hi, I am taking classes here at inceptez\""
      ],
      "metadata": {
        "id": "CXYj81F4ImSS"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated = generate_seq(model,tokenizer,seq_length, in_text,10)"
      ],
      "metadata": {
        "id": "E-mxZ7rXJEN3"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5mOor4JAJLhQ",
        "outputId": "4adf5629-cd64-4567-b086-fb38afd80652"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hi, I am taking classes here at inceptez some elements confirmed idea under poetry had better be included'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gcQmuCjfOUGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TOHf-F5BKtpP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}